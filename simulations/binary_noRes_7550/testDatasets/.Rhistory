visit3Time <- 6
###################################################################################
##SIMULATIONS##
###################################################################################
estimates <- matrix(NA, nrow = K, ncol = 7)
SE <- matrix(NA, nrow = K, ncol = 7)
PG_redefineInt <- rep(NA,3) #the first column will be the simulation number,
#the second column will be the Beta estimate by PG
#the third column will be the SE for PG
nties <- matrix(NA, nrow = K, ncol = 3)
for(k in 1:K){
set.seed(simSeeds[k])
###################################################################################
##Generation of Z (random treatment assignment: 1 if control, 0 if treatment)##
###################################################################################
data <- data.frame(Z=rbinom(n,size=1,prob=pTreatment))
###################################################################################
##Generation of C (censoring time, the last visit the subject attends)##
###################################################################################
data$C <- sample(x=0:m,size=n,replace = TRUE, prob = c(.08,.1,.1,.72))
###################################################################################
##Generation of T (frailty time)##
###################################################################################
##Failure time generated from the Weibull hazard
a <- 2
b <- 100
u <- -log(runif(n))
exb <- exp(trueBeta*data$Z)
data$Tcont <- NA
for(i in 1:n){
data$Tcont[i] <- uniroot(froot, interval=c(1.e-14, 1e04), u = u[i], exb = exb[i], a=a, b=b)$root
}
rm(a,b,u,exb)
#hist(data$Tcont)
#summary(data$Tcont)
###################################################################################
##Generation of T' (grouped frailty time)##
###################################################################################
data$Tgrouped <- 10000
for(i in 1:n){
if(data$Tcont[i]==0){
data$Tgrouped[i] <- 0
}else if(0<data$Tcont[i]&data$Tcont[i]<=visit1Time){
data$Tgrouped[i] <- 1
}else if(visit1Time<data$Tcont[i] & data$Tcont[i]<=visit2Time){
data$Tgrouped[i] <- 2
}else if(visit2Time<data$Tcont[i] & data$Tcont[i]<=visit3Time){
data$Tgrouped[i] <- 3
}
}
###################################################################################
##Calculate delta (censoring indicator) and V (visit time depending on delta)##
###################################################################################
data$delta <- 1
data$delta[data$Tgrouped>data$C] <- 0
data$V <- data$delta*data$Tgrouped + (1-data$delta)*data$C
#table(data$C)/n
#table(data$Tgrouped)/n
#table(data$delta,data$V)/n
#temp <- table(data$delta,data$V)/n
#sum(temp[1,1:3]) #proportion of n subjects who dropout early
#temp[1,4] #proportion of n subjects who are adminstratively censored
#sum(temp[2,]) #proportion who are observed to be frail
data <- subset(data, V!=0)
temp <- table(data$delta,data$V)/n
if (nrow(temp)!=2) {
estimates[k,] <- rep(NA,times=4)
warning(paste(k, ":Either no censoring or no failure."))
} else if (ncol(temp)!=m) {
estimates[k,] <- rep(NA,times=4)
warning(paste(k, ":There are visits where no people are censored AND no people fail."))
} else {
###################################################################################
##Apply PG method and CoxPH methods##
###################################################################################
nties[k,] <- temp[2,]*n
##CoxPH methods
mod.efron <- coxph(Surv(V, delta) ~ Z, ties = "efron", data=data)
coefs.efron <- summary(mod.efron)$coef[,1]
se.efron <- summary(mod.efron)$coef[,3]
mod.breslow <- update(mod.efron, ties = "breslow")
coefs.breslow <- summary(mod.breslow)$coef[,1]
se.breslow <- summary(mod.breslow)$coef[,3]
mod.Rexact <- update(mod.efron, ties = "exact")
coefs.Rexact <- summary(mod.Rexact)$coef[,1]
se.Rexact <- summary(mod.Rexact)$coef[,3]
##Felix
mod.Felix <- optim(0, logPL, method="BFGS", data=data, control=list(fnscale=-1), gr = ExactGradient, hessian = FALSE)
coefs.Felix <- mod.Felix$par
numHess.Felix <- jacobian(func = ExactGradient, x = coefs.Felix, method = "Richardson", data = data)
se.Felix <- sqrt(diag(solve(-numHess.Felix)))
##Laplace
mod.Laplace <- optim(0, laplacePL, method="BFGS", data=data, control=list(fnscale=-1), hessian = FALSE)
coefs.Laplace <- mod.Laplace$par
numHess.Laplace <- hessian(func = laplacePL, x = coefs.Laplace, method = "Richardson", data = data)
se.Laplace <- sqrt(diag(solve(-numHess.Laplace)))
##Laguerre
mod.Laguerre <- optim(0, exactPL, method="BFGS", data=data, control=list(fnscale=-1), hessian = FALSE)
coefs.Laguerre <- mod.Laguerre$par
numHess.Laguerre <- hessian(func = exactPL, x = coefs.Laguerre, method = "Richardson", data = data)
se.Laguerre <- sqrt(diag(solve(-numHess.Laguerre)))
##PG method
ek <- unname(with(data,table(V, delta))[,2])
Nfollowup <- 3
N <- nrow(data)
dimBeta <- 1
dat <- data.frame(id = 1:nrow(data), data$V, data$delta, data$Z) ##dat will be data in long format
names(dat) <- c("id", "V","delta","Z")
seqvar <- 1:dat$V[1] ##will define as in Jenkins STB
for(i in 2:nrow(dat)){
seqvar <- c(seqvar,1:dat$V[i])
}
dat <- dat[rep(1:nrow(dat),times=dat$V),]
dat$seqvar <- seqvar
dat$y.ij <- 0 ##we will define y.ij as in Jenkin's STB
dat$y.ij[dat$delta == 1 & dat$seqvar == dat$V] <- 1
dat <- dat[,-c(2,3)]
modPG <-  try(optim(c(rep(0, dimBeta), log(-log(1-(1+ek)/N))), PGloglik, gr = PGgradient, method="BFGS", data=dat, control=list(fnscale=-1), hessian = FALSE), silent=TRUE)
coefs.pg <-  modPG$par
se.pg <- sqrt(diag(solve(-PGhessian(dat, coefs.pg))))
coefs.pg <- coefs.pg[1]
se.pg <- se.pg[1]
##Commenting out on 10/16/16 to put in PG-manual, as PG-glm had trouble in the CHS sims
#mod.pg <- glm(formula = y.ij ~ -1 + as.factor(seqvar) + Z, data = dat, family = binomial(link = cloglog))
#coefs.pg <-  coef(summary(mod.pg))[grepl("Z$",row.names(coef(summary(mod.pg)))), 1]
#se.pg <- coef(summary(mod.pg))[grepl("Z$",row.names(coef(summary(mod.pg)))), 2]
estimates[k,] <- c(coefs.efron,coefs.breslow,coefs.Felix,coefs.Laguerre,coefs.Rexact,coefs.pg, coefs.Laplace)
SE[k,] <- c(se.efron, se.breslow, se.Felix, se.Laguerre, se.Rexact, se.pg, se.Laplace)
#if there are any intervals with no failures, also run PG method after redefining the intervals so that all have failures
if (temp[2,1]==0 | temp[2,2]==0 | temp[2,3]==0) {
data2 <- data
j <- 1
NoFailureInt <- which(temp[2,] == 0)
for(i in 1:3){
if(i %in%  NoFailureInt){
data2$V[data2$V>=j] <- data2$V[data2$V>=j] - 1
} else {
j <- j + 1
}
}
##PG method
data2 <- subset(data2, V != 0)
ek <- unname(with(data2,table(V, delta))[,2])
Nfollowup <- length(ek)
N <- nrow(data2)
dimBeta <- 1
dat <- data.frame(id = 1:nrow(data2), data2$V, data2$delta, data2$Z) ##dat will be data in long format
names(dat) <- c("id","V","delta","Z")
seqvar <- 1:dat$V[1] ##will define as in Jenkins STB
for(i in 2:nrow(dat)){
seqvar <- c(seqvar,1:dat$V[i])
}
dat <- dat[rep(1:nrow(dat),times=dat$V),]
dat$seqvar <- seqvar
dat$y.ij <- 0 ##we will define y.ij as in Jenkin's STB
dat$y.ij[dat$delta == 1 & dat$seqvar == dat$V] <- 1
dat <- dat[,-c(2,3)]
modPG <-  try(optim(c(rep(0, dimBeta), log(-log(1-(1+ek)/N))), PGloglik, gr = PGgradient, method="BFGS", data=dat, control=list(fnscale=-1), hessian = FALSE), silent=TRUE)
coefs.pg <-  modPG$par
se.pg <- sqrt(diag(solve(-PGhessian(dat, coefs.pg))))
coefs.pg <- coefs.pg[1]
se.pg <- se.pg[1]
##mod.pg <- glm(formula = y.ij ~ -1 + as.factor(seqvar) + Z, data = dat, family = binomial(link = cloglog))
##coefs.pg <-  coef(summary(mod.pg))[grepl("Z$",row.names(coef(summary(mod.pg)))), 1]
##se.pg <- coef(summary(mod.pg))[grepl("Z$",row.names(coef(summary(mod.pg)))), 2]
PG_redefineInt <- rbind(PG_redefineInt, c(k,coefs.pg,se.pg))
}
}
}
warnings()
rm(list=ls())
seed <- 765576129
###################################################################################
##LIBRARIES##
###################################################################################
require(survival)
require(MASS)
require(gaussquad)
require(numDeriv)
############################################################################################################################################
##FUNCTIONS##
############################################################################################################################################
hazard <- function(t, a, b, exb) exb * a * (t/b)^(a-1)
cumhaz <- function(t, a, b, exb) exb * b * (t/b)^a
froot <- function(x, u, ...) sqrt(cumhaz(x, ...)) - sqrt(u)
##Functions for applying Felix approximation
approxFun <- function(d, riskSet, Beta){
riskSet$r <- exp(riskSet$Z*Beta)
sumRisk <- sum(riskSet$r[(d+1):nrow(riskSet)])
val <- sum(log(1-exp(-riskSet$r[1:d]/sumRisk*(d+1))))
return(val)
}
logPL <- function(Beta, data){
logPL <- 0
failureVisits <- sort(unique(data$V[data$delta == 1]))
for (v in 1:length(failureVisits)){
riskSet <- subset(data, V >= failureVisits[v])
riskSet.top <- subset(riskSet, V == failureVisits[v] & delta == 1)
d <- nrow(riskSet.top)
riskSet.bottom <- subset(riskSet, !(V == failureVisits[v] & delta == 1))
riskSet <- rbind(riskSet.top, riskSet.bottom)
logPL <- logPL + approxFun(d, riskSet, Beta)
}
return(logPL)
}
ExactGradient <- function(Beta, data){ ##Gradient to help optim estimate Exact model parameters
grad <- 0
failureVisits <- sort(unique(data$V[data$delta == 1]))
for (v in 1:length(failureVisits)){
riskSet <- subset(data, V >= failureVisits[v])
riskSet.top <- subset(riskSet, V == failureVisits[v] & delta == 1)
d <- nrow(riskSet.top)
riskSet.bottom <- subset(riskSet, !(V == failureVisits[v] & delta == 1))
riskSet <- rbind(riskSet.top, riskSet.bottom)
riskSet$r <- exp(riskSet$Z*Beta)
sumRisk <- sum(riskSet$r[(d+1):nrow(riskSet)])
a.k <- riskSet$r[1:d]/sumRisk
grad <- grad + (d + 1)*sum(exp(-a.k*(d+1))/(1-exp(-a.k*(d+1)))*(sumRisk*riskSet$r[1:d]*riskSet$Z[1:d]-riskSet$r[1:d]*sum(riskSet$r[(d+1):nrow(riskSet)]*riskSet$Z[(d+1):nrow(riskSet)]))/sumRisk^2)
}
return(grad)
}
##Functions for applying Laguerre approximation
exactPL.contribution <- function(x, d, riskSet, Beta){
logval <- 0
riskSet$r <- exp(riskSet$Z*Beta)
sumRisk <- sum(riskSet$r[(d+1):nrow(riskSet)])
for (i in 1:d){
logval <- logval + log(1-exp(-riskSet$r[i]*x/sumRisk))
}
return(exp(logval))
}
exactPL <- function(Beta, data){
logPL <- 0
failureVisits <- sort(unique(data$V[data$delta == 1]))
for (v in 1:length(failureVisits)){
riskSet <- subset(data, V >= failureVisits[v])
riskSet.top <- subset(riskSet, V == failureVisits[v] & delta == 1)
d <- nrow(riskSet.top)
riskSet.bottom <- subset(riskSet, !(V == failureVisits[v] & delta == 1))
riskSet <- rbind(riskSet.top, riskSet.bottom)
logPL <- logPL + log(glaguerre.quadrature(exactPL.contribution, orderNrules[[orderN]], alpha = 0, lower = 0, upper = Inf,
weighted = TRUE, d = d, riskSet = riskSet, Beta = Beta))
}
return(logPL)
}
orderN <- 100
alpha <- 0
orderNrules <- glaguerre.quadrature.rules(orderN, alpha, normalized=FALSE)
##Functions for applying Laplace approximation
laplaceFun <- function(x, a.j){
sum(a.j/(exp(a.j*x)-1)) - 1
}
laplacePL <- function(Beta, data){
logPL <- 0
failureVisits <- sort(unique(data$V[data$delta == 1])) ##get the follow-up visits where failures are observed
for (v in 1:length(failureVisits)){
riskSet <- subset(data, V >= failureVisits[v]) ##consider only those who are at risk
riskSet.top <- subset(riskSet, V == failureVisits[v] & delta == 1)
d <- nrow(riskSet.top) ##number of people who failed
riskSet.bottom <- subset(riskSet, !(V == failureVisits[v] & delta == 1))
riskSet <- rbind(riskSet.top, riskSet.bottom) ##the first d rows are the people who failed, the following
##rows are the other people in the risk set
riskSet$r <- exp(riskSet$Z*Beta) ##compute every person's risk score
sumRisk <- sum(riskSet$r[(d+1):nrow(riskSet)]) ##add the risk scores of the people in the risk set who didn't fail
a.j <- riskSet$r[1:d]/sumRisk
tStar <- uniroot(f = laplaceFun, interval = c(0.01,d), extendInt = "yes", a.j = a.j)$root
sigmaStar <- sum(a.j^2 * exp(a.j*tStar)/(exp(a.j*tStar) - 1)^2)
logPL <- logPL - 1/2 * log(sigmaStar) + sum(log(1-exp(-a.j*tStar))) - tStar + pnorm(0, mean = tStar, sd = 1/sqrt(sigmaStar), lower.tail = FALSE, log.p = TRUE)
}
return(logPL)
}
##Functions for PG model
PGloglik <- function(x, data){
k <- Nfollowup
p <- length(x) - k ##number of Beta parameters
pterm <- rep(0, nrow(data))
for (i in 1:p) pterm <- pterm + (data[,i+1] * x[i]) ##first column of data is id
sterm <- rep(0, nrow(data))
for (i in 1:k) sterm <- sterm + (data$seqvar == i) * x[i+p]
h.jx <- 1 - exp(-exp(pterm + sterm))
val <-  sum(data$y.ij*log(h.jx) + (1-data$y.ij)*log(1-h.jx))
return(val)
}
##Gradient to help optim estimate PG model parameters
PGgradient <- function(x, data){
grad <- rep(NA, length(x))
k <- Nfollowup
p <- length(x) - k ##number of Beta's to be estimated
pterm <- rep(0, nrow(data))
for (i in 1:p) pterm <- pterm + (data[,i+1] * x[i]) ##first column is id
sterm <- rep(0, nrow(data))
for (i in 1:k) sterm <- sterm + (data$seqvar == i) * x[i+p]
alpha.ij <- exp(pterm + sterm)
h.ij <- 1 - exp(-alpha.ij)
for (i in 1:p) grad[i] <- sum(data$y.ij*exp(-alpha.ij)*alpha.ij/(h.ij)*data[,i+1] - (1-data$y.ij)*exp(-alpha.ij)*alpha.ij/(1-h.ij)*data[,i+1])
for (i in 1:k) grad[p+i] <- sum((data$y.ij * exp(-alpha.ij)*alpha.ij/h.ij - (1-data$y.ij)*exp(-alpha.ij)*alpha.ij/(1-h.ij))*(data$seqvar == i))
return(grad)
}
##Hessian for getting standard errors
PGhessian <- function(data, coefs.pg){
hessian <- matrix(NA, nrow = Nfollowup + dimBeta, ncol = Nfollowup + dimBeta)
pterm <- rep(0, nrow(data))
for (i in 1:dimBeta) pterm <- pterm + (data[,i+1] * coefs.pg[i]) ##first column is id
sterm <- rep(0, nrow(data))
for (i in 1:Nfollowup) sterm <- sterm + (data$seqvar == i) * coefs.pg[i+dimBeta]
alpha.ij <- exp(pterm + sterm)
h.ij <- 1 - exp(-alpha.ij)
x.ij <- 1/(exp(alpha.ij)-1)-alpha.ij*exp(alpha.ij)/(exp(alpha.ij)-1)^2
for (i in 1:dimBeta){
for (j in 1:dimBeta){
hessian[i,j] <- sum(data$y.ij*data[,1+i]*data[,1+j]*alpha.ij*x.ij-(1-data$y.ij)*data[,1+i]*data[,1+j]*alpha.ij)
}
}
for (i in 1:Nfollowup){
for (j in 1:Nfollowup){
if (i != j) {
hessian[dimBeta+i,dimBeta+j] <- 0
} else {
hessian[dimBeta+i,dimBeta+i]<-sum((data$seqvar==i) * (data$y.ij*alpha.ij*x.ij-alpha.ij*(1-data$y.ij)))
}
}
}
for (i in 1:dimBeta){
for (j in 1:Nfollowup){
hessian[i,j+dimBeta] <- hessian[j+dimBeta, i] <- sum((data$seqvar==j)*(data$y.ij*alpha.ij*data[,1+i]*x.ij-(1-data$y.ij)*alpha.ij*data[,1+i]))
}
}
return(hessian)
}
############################################################################################################################################
##INPUTS##
############################################################################################################################################
K <- 100
m <- 3 ##number of follow-up visits
pTreatment <- 0.5 ##probability of being assigned to treatment group
trueBeta <- 2 ##treatment effect
n <- 500 ##sample size of each simulated randomized trial
set.seed(seed)
simSeeds <- sample(10^9,K)
visit1Time <- 2
visit2Time <- 4
visit3Time <- 6
###################################################################################
##SIMULATIONS##
###################################################################################
estimates <- matrix(NA, nrow = K, ncol = 7)
SE <- matrix(NA, nrow = K, ncol = 7)
PG_redefineInt <- rep(NA,3) #the first column will be the simulation number,
#the second column will be the Beta estimate by PG
#the third column will be the SE for PG
nties <- matrix(NA, nrow = K, ncol = 3)
for(k in 1:K){
set.seed(simSeeds[k])
###################################################################################
##Generation of Z (random treatment assignment: 1 if control, 0 if treatment)##
###################################################################################
data <- data.frame(Z=rbinom(n,size=1,prob=pTreatment))
###################################################################################
##Generation of C (censoring time, the last visit the subject attends)##
###################################################################################
data$C <- sample(x=0:m,size=n,replace = TRUE, prob = c(.08,.1,.1,.72))
###################################################################################
##Generation of T (frailty time)##
###################################################################################
##Failure time generated from the Weibull hazard
a <- 2
b <- 100
u <- -log(runif(n))
exb <- exp(trueBeta*data$Z)
data$Tcont <- NA
for(i in 1:n){
data$Tcont[i] <- uniroot(froot, interval=c(1.e-14, 1e04), u = u[i], exb = exb[i], a=a, b=b)$root
}
rm(a,b,u,exb)
#hist(data$Tcont)
#summary(data$Tcont)
###################################################################################
##Generation of T' (grouped frailty time)##
###################################################################################
data$Tgrouped <- 10000
for(i in 1:n){
if(data$Tcont[i]==0){
data$Tgrouped[i] <- 0
}else if(0<data$Tcont[i]&data$Tcont[i]<=visit1Time){
data$Tgrouped[i] <- 1
}else if(visit1Time<data$Tcont[i] & data$Tcont[i]<=visit2Time){
data$Tgrouped[i] <- 2
}else if(visit2Time<data$Tcont[i] & data$Tcont[i]<=visit3Time){
data$Tgrouped[i] <- 3
}
}
###################################################################################
##Calculate delta (censoring indicator) and V (visit time depending on delta)##
###################################################################################
data$delta <- 1
data$delta[data$Tgrouped>data$C] <- 0
data$V <- data$delta*data$Tgrouped + (1-data$delta)*data$C
#table(data$C)/n
#table(data$Tgrouped)/n
#table(data$delta,data$V)/n
#temp <- table(data$delta,data$V)/n
#sum(temp[1,1:3]) #proportion of n subjects who dropout early
#temp[1,4] #proportion of n subjects who are adminstratively censored
#sum(temp[2,]) #proportion who are observed to be frail
data <- subset(data, V!=0)
temp <- table(data$delta,data$V)/n
if (nrow(temp)!=2) {
estimates[k,] <- rep(NA,times=4)
warning(paste(k, ":Either no censoring or no failure."))
} else if (ncol(temp)!=m) {
estimates[k,] <- rep(NA,times=4)
warning(paste(k, ":There are visits where no people are censored AND no people fail."))
} else {
###################################################################################
##Apply PG method and CoxPH methods##
###################################################################################
nties[k,] <- temp[2,]*n
##CoxPH methods
mod.efron <- coxph(Surv(V, delta) ~ Z, ties = "efron", data=data)
coefs.efron <- summary(mod.efron)$coef[,1]
se.efron <- summary(mod.efron)$coef[,3]
mod.breslow <- update(mod.efron, ties = "breslow")
coefs.breslow <- summary(mod.breslow)$coef[,1]
se.breslow <- summary(mod.breslow)$coef[,3]
mod.Rexact <- update(mod.efron, ties = "exact")
coefs.Rexact <- summary(mod.Rexact)$coef[,1]
se.Rexact <- summary(mod.Rexact)$coef[,3]
##Felix
mod.Felix <- optim(0, logPL, method="BFGS", data=data, control=list(fnscale=-1), gr = ExactGradient, hessian = FALSE)
coefs.Felix <- mod.Felix$par
numHess.Felix <- jacobian(func = ExactGradient, x = coefs.Felix, method = "Richardson", data = data)
se.Felix <- sqrt(diag(solve(-numHess.Felix)))
##Laplace
mod.Laplace <- optim(0, laplacePL, method="BFGS", data=data, control=list(fnscale=-1), hessian = FALSE)
coefs.Laplace <- mod.Laplace$par
numHess.Laplace <- hessian(func = laplacePL, x = coefs.Laplace, method = "Richardson", data = data)
se.Laplace <- sqrt(diag(solve(-numHess.Laplace)))
##Laguerre
mod.Laguerre <- optim(0, exactPL, method="BFGS", data=data, control=list(fnscale=-1), hessian = FALSE)
coefs.Laguerre <- mod.Laguerre$par
numHess.Laguerre <- hessian(func = exactPL, x = coefs.Laguerre, method = "Richardson", data = data)
se.Laguerre <- sqrt(diag(solve(-numHess.Laguerre)))
##PG method
ek <- unname(with(data,table(V, delta))[,2])
Nfollowup <- 3
N <- nrow(data)
dimBeta <- 1
dat <- data.frame(id = 1:nrow(data), data$V, data$delta, data$Z) ##dat will be data in long format
names(dat) <- c("id", "V","delta","Z")
seqvar <- 1:dat$V[1] ##will define as in Jenkins STB
for(i in 2:nrow(dat)){
seqvar <- c(seqvar,1:dat$V[i])
}
dat <- dat[rep(1:nrow(dat),times=dat$V),]
dat$seqvar <- seqvar
dat$y.ij <- 0 ##we will define y.ij as in Jenkin's STB
dat$y.ij[dat$delta == 1 & dat$seqvar == dat$V] <- 1
dat <- dat[,-c(2,3)]
modPG <-  try(optim(c(rep(0, dimBeta), log(-log(1-(1+ek)/N))), PGloglik, gr = PGgradient, method="BFGS", data=dat, control=list(fnscale=-1), hessian = FALSE), silent=TRUE)
coefs.pg <-  modPG$par
se.pg <- sqrt(diag(solve(-PGhessian(dat, coefs.pg))))
coefs.pg <- coefs.pg[1]
se.pg <- se.pg[1]
##Commenting out on 10/16/16 to put in PG-manual, as PG-glm had trouble in the CHS sims
#mod.pg <- glm(formula = y.ij ~ -1 + as.factor(seqvar) + Z, data = dat, family = binomial(link = cloglog))
#coefs.pg <-  coef(summary(mod.pg))[grepl("Z$",row.names(coef(summary(mod.pg)))), 1]
#se.pg <- coef(summary(mod.pg))[grepl("Z$",row.names(coef(summary(mod.pg)))), 2]
estimates[k,] <- c(coefs.efron,coefs.breslow,coefs.Felix,coefs.Laguerre,coefs.Rexact,coefs.pg, coefs.Laplace)
SE[k,] <- c(se.efron, se.breslow, se.Felix, se.Laguerre, se.Rexact, se.pg, se.Laplace)
#if there are any intervals with no failures, also run PG method after redefining the intervals so that all have failures
if (temp[2,1]==0 | temp[2,2]==0 | temp[2,3]==0) {
data2 <- data
j <- 1
NoFailureInt <- which(temp[2,] == 0)
for(i in 1:3){
if(i %in%  NoFailureInt){
data2$V[data2$V>=j] <- data2$V[data2$V>=j] - 1
} else {
j <- j + 1
}
}
##PG method
data2 <- subset(data2, V != 0)
ek <- unname(with(data2,table(V, delta))[,2])
Nfollowup <- length(ek)
N <- nrow(data2)
dimBeta <- 1
dat <- data.frame(id = 1:nrow(data2), data2$V, data2$delta, data2$Z) ##dat will be data in long format
names(dat) <- c("id","V","delta","Z")
seqvar <- 1:dat$V[1] ##will define as in Jenkins STB
for(i in 2:nrow(dat)){
seqvar <- c(seqvar,1:dat$V[i])
}
dat <- dat[rep(1:nrow(dat),times=dat$V),]
dat$seqvar <- seqvar
dat$y.ij <- 0 ##we will define y.ij as in Jenkin's STB
dat$y.ij[dat$delta == 1 & dat$seqvar == dat$V] <- 1
dat <- dat[,-c(2,3)]
modPG <-  try(optim(c(rep(0, dimBeta), log(-log(1-(1+ek)/N))), PGloglik, gr = PGgradient, method="BFGS", data=dat, control=list(fnscale=-1), hessian = FALSE), silent=TRUE)
coefs.pg <-  modPG$par
se.pg <- sqrt(diag(solve(-PGhessian(dat, coefs.pg))))
coefs.pg <- coefs.pg[1]
se.pg <- se.pg[1]
##mod.pg <- glm(formula = y.ij ~ -1 + as.factor(seqvar) + Z, data = dat, family = binomial(link = cloglog))
##coefs.pg <-  coef(summary(mod.pg))[grepl("Z$",row.names(coef(summary(mod.pg)))), 1]
##se.pg <- coef(summary(mod.pg))[grepl("Z$",row.names(coef(summary(mod.pg)))), 2]
PG_redefineInt <- rbind(PG_redefineInt, c(k,coefs.pg,se.pg))
}
}
}
warnings()
rm(list=ls())
